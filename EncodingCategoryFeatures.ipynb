{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4c2dad",
   "metadata": {},
   "source": [
    "`Encoding Category Features`\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0bf98",
   "metadata": {},
   "source": [
    "### Method\n",
    "\n",
    "- After I imported the dataset I seperated the features (X) from the target variable column (y). \n",
    "\n",
    "- I used the label encoder to encode the target (y).\n",
    "\n",
    "- I then implemented the different encoders for each given task & split the data between train and test.\n",
    "\n",
    "- I used `Categorical Naive Bayes` and `Bernoulli Naive Bayes` provided by scikit-learn to perform predictions on the dataset and finally test the accuracy of those predictions by comparing them back to the target y test split.\n",
    "\n",
    "\n",
    "\n",
    "------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8f847",
   "metadata": {},
   "source": [
    "#### Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898e048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports required for the tasks, Naive Bayes libraries and the Encoder libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB, BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f60041",
   "metadata": {},
   "source": [
    "## Task 1\n",
    " - In the first section I encode the data set using `OrdinalEncoder` and use `CategoricalNB`.\n",
    " - For the second part of the task I use `OneHotEncoder` & `BernoulliNB` to run prediction on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20cec9",
   "metadata": {},
   "source": [
    "#### Load 'breast-cancer.csv' Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952678fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the breast-cancer.csv file\n",
    "\n",
    "data = pd.read_csv('breast-cancer.csv')\n",
    "data # Print data table\n",
    "\n",
    "rand = 29; # int to change random_state when splitting the datasets for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb74d96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig',\n",
      "       'breast', 'breast-quad', 'irradiat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Seperate data features from the target variable\n",
    "\n",
    "X = data\n",
    "y = X.pop('Class').values\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246747b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LabelEncode the target variable y: Class\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "y = lab_encoder.fit_transform(y)\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9632d4",
   "metadata": {},
   "source": [
    "### Ordinal Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba59682b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 5., ..., 0., 2., 0.],\n",
       "       [2., 2., 3., ..., 1., 5., 0.],\n",
       "       [2., 2., 3., ..., 0., 2., 0.],\n",
       "       ...,\n",
       "       [4., 0., 3., ..., 1., 3., 0.],\n",
       "       [2., 0., 5., ..., 0., 2., 0.],\n",
       "       [3., 0., 5., ..., 0., 2., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement SciKit Ordinal Encoder\n",
    "\n",
    "ord_encoder = OrdinalEncoder(categories = 'auto')\n",
    "dataOE = ord_encoder.fit_transform(X)\n",
    "dataOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a0e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 9)\n",
      "(143, 9)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets 50:50 \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataOE, y, test_size=0.5, random_state=rand)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c7db38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catNB = CategoricalNB(fit_prior=True,alpha = 0.0001)    \n",
    "data_catNB = catNB.fit(X_train, y_train)\n",
    "\n",
    "y_dash = data_catNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce133a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.13\n",
      "Confusion matrix:\n",
      "[[83 17]\n",
      " [20 23]]\n"
     ]
    }
   ],
   "source": [
    "# Check Accuracy using Ordinal encoding and Categorical Naive Bayes\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_dash)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_dash)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc38cf8",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9246bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform breast-cancer dataset using OnHot encoding\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output = False)\n",
    "dataOH = onehot_encoder.fit_transform(X)\n",
    "\n",
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataOH, y, test_size=0.5, random_state=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c9799e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data using Bernoulli \n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb_data = bnb.fit(X_train, y_train)\n",
    "\n",
    "# Run bernoulli pred on X test data set\n",
    "y_dash =bnb_data.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a54556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.13\n",
      "Confusion matrix:\n",
      "[[82 18]\n",
      " [19 24]]\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy using One Hot encoding and Bernooulli Naive Bayes\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_dash)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "confusion = confusion_matrix(y_test, y_dash)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04dc7d5",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "### Cat Boost Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1555ce6",
   "metadata": {},
   "source": [
    "- For the second task I encode the data set using `CatBoostEncoder` and use `CategoricalNB` to run prediction tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed7e2198",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'category_encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fy/7s2r7fq17zv4y61mv1xy844h0000gn/T/ipykernel_51526/743820814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define catboost encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcbe_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_boost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoostEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# Define catboost encoder\n",
    "cbe_encoder = ce.cat_boost.CatBoostEncoder()\n",
    "\n",
    "# Fit the dataset to CatBoost \n",
    "dataCBE = cbe_encoder.fit_transform(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataCBE, y, test_size=0.5, random_state=rand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Categorical NB model and fit using the training data\n",
    "catNB = CategoricalNB(fit_prior=True,alpha = 0.0001)    \n",
    "catBoost_catNB = catNB.fit(X_train, y_train)\n",
    "# Run NB prediction on Test set\n",
    "y_dash = catBoost_catNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecedf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy using SkLearn library\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_dash)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_dash)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e525464",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "- For this task I use the same three Encoders and Naive Bayes models above, I split the datasets to training and testing before fitting the encoders. The encoders are fitted using the training data only.\n",
    "\n",
    "Firstly I created a 2D list of the category features to apply later on the encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the categories for X manually (features)\n",
    "data_cat = [  ['20-29', '30-39', '40-49', '50-59', '60-69', '70-79'],\n",
    "                ['lt40', 'ge40', 'premeno'],\n",
    "                ['0-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54'], # tumor-size\n",
    "                ['0-2', '3-5', '6-8', '9-11', '12-14', '15-17', '24-26'], # inv-nodes\n",
    "                ['yes', 'no'], # node-caps\n",
    "                ['1', '2', '3'], # deg-malig: maligency, Higher number indicates greater\n",
    "                ['left', 'right'], # breast\n",
    "                ['left_up', 'left_low', 'right_up', 'right_low', 'central'], # breast-quad\n",
    "                ['yes', 'no']\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ca638",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934064af",
   "metadata": {},
   "source": [
    "#### Design Decision: \n",
    "The `CategoricalNB` library does not handle unknown values. For the `OrdinalEncoder` I decided on the approach of temporarily removing any row that has unknown values or '?' inputted as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97481e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset & Set X and y Values\n",
    "data = pd.read_csv('breast-cancer.csv')\n",
    "# Replace \"?\" with NaN\n",
    "data = data.replace('?', np.nan)\n",
    "\n",
    "# Drop all rows with NaN values\n",
    "data  = data.dropna()\n",
    "\n",
    "X = data\n",
    "y = X.pop('Class').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset 50:50 for Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbc6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncode the y Target\n",
    "lab_encoder = LabelEncoder()\n",
    "\n",
    "y_train = lab_encoder.fit_transform(y_train)\n",
    "y_test = lab_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new OrdinalEncoder(): fit with training data & manually set categories\n",
    "ord_encoder2 = OrdinalEncoder(categories = data_cat)\n",
    "ord_encoder2 = ord_encoder2.fit(X_train)\n",
    "\n",
    "\n",
    "X_train = ord_encoder2.transform(X_train)\n",
    "X_test = ord_encoder2.transform(X_test)\n",
    "\n",
    "# ------------------\n",
    "\n",
    "# --- Used for testing: To check Features listed in both Train and Test\n",
    "\n",
    "# print(ord_encoder2.categories_)\n",
    "\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     print(f\"Feature {i}: {np.unique(X_train[:, i])}\")\n",
    "    \n",
    "# for i in range(X_test.shape[1]):\n",
    "#     print(f\"Feature {i}: {np.unique(X_test[:, i])}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531fe37",
   "metadata": {},
   "source": [
    "#### Design Decision:\n",
    "\n",
    "In order to have the same amount of category features for both test and train when running the CatNB, I manually set the minimum number of categories for each feature in order to avoid index out of bound issues arising.\n",
    "\n",
    "- For example in the data set, inv-node contains one 24-26 sample, this will always lead to either the X_test set or the X_train set having one more category in this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "catNB = CategoricalNB(fit_prior=True,alpha = 0.0001, min_categories = [6,3,11,7,2,3,2,5,2]) \n",
    "data_catNB = catNB.fit(X_train, y_train)                                                   \n",
    "\n",
    "y_dash = data_catNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Accuracy using Ordinal encoding and Categorical Naive Bayes\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_dash)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_dash)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be4f2b1",
   "metadata": {},
   "source": [
    "### OneHot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f7b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset & Set X and y Values\n",
    "\n",
    "data = pd.read_csv('breast-cancer.csv')\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Split dataset 50:50 for Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot encode X_train and X_test\n",
    "\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train = onehot_encoder.fit_transform(X_train)\n",
    "X_test = onehot_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b16e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit The training data to Naive Bayes Model.\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "# Run bernoulli prediction on X test data set\n",
    "y_dash = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb48785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_dash)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "confusion = confusion_matrix(y_test, y_dash)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfd1d3",
   "metadata": {},
   "source": [
    "### Cat Boost Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e13309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset & Set X and y Values\n",
    "\n",
    "data = pd.read_csv('breast-cancer.csv')\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86458d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ac166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncode the y Target\n",
    "lab_encoder = LabelEncoder()\n",
    "\n",
    "y_train = lab_encoder.fit_transform(y_train)\n",
    "y_test = lab_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# Define catboost encoder\n",
    "cbe_encoder2 = ce.cat_boost.CatBoostEncoder()\n",
    "\n",
    "X_train = cbe_encoder2.fit_transform(X_train, y_train)\n",
    "X_test = cbe_encoder2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Categorical NB for Cat Boost encoder\n",
    "catNB_CBE = CategoricalNB()\n",
    "\n",
    "# Fit training data to the model & run prediction on test data\n",
    "catBoost_catNB = catNB.fit(X_train, y_train)\n",
    "y_dash = catBoost_catNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_dash)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "confusion = confusion_matrix(y_test, y_dash)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b8e1d",
   "metadata": {},
   "source": [
    "## Task 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e05264f",
   "metadata": {},
   "source": [
    "#### Method - \n",
    "- To test the accuracy of each of the methods above I ran each implementation 10 times using a different random_state value in order the change the X_train and X_test split, this value was changed using the `rand` variable initialised in the first cell.\n",
    "\n",
    "- Following this I then calculated the average accuracy result for each of the encoders for the two different implementations: encoding before and encoding after splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (rand value used):1  -  2  -  23   -  14  -  6  -   17  -  47  -  11  -  35  -  29\n",
    "\n",
    "CatBoostAfter = [74.13, 71.33, 73.43, 72.03, 68.53, 72.73, 75.52, 69.93, 69.93, 72.73]\n",
    "CatBoostBefore = [74.13, 71.33, 73.43, 72.03, 68.53, 72.73, 75.52, 69.93, 69.93, 72.73] \n",
    "\n",
    "OneHotAfter = [71.33, 72.03, 69.23, 74.13, 71.33,  72.73, 78.32, 71.33, 72.03, 74.13]\n",
    "OneHotBefore = [71.33, 72.03, 69.23, 74.13, 72.03, 72.73, 79.02, 71.33, 72.03, 74.13]\n",
    "\n",
    "OrdinalAfter = [74.82, 70.50, 69.78, 71.94, 68.35, 73.38, 76.26, 76.26, 70.50, 71.22]\n",
    "OrdinalBefore = [ 67.83, 67.13, 68.53, 73.43, 69.23, 69.93, 72.73, 72.03, 74.13, 74.13]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b0b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Average of List\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec380cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the average for each list of results\n",
    "print(\"CatBoost Encoding\")\n",
    "CB_AfterAverage = Average(CatBoostAfter)\n",
    "print(\"After: \" + str(CB_AfterAverage)+ \"%\")\n",
    "CB_Before_Average = Average(CatBoostBefore)\n",
    "print(\"Before: \" + str(CB_Before_Average)+ \"%\")\n",
    "\n",
    "print(\"---------------------\")\n",
    "\n",
    "\n",
    "print(\"OneHot Encoding\")\n",
    "OH_After_Average = Average(OneHotAfter)\n",
    "print(\"After: \" + str(OH_After_Average)+ \"%\")\n",
    "OH_Before_Average = Average(OneHotBefore)\n",
    "print(\"Before: \" + str(OH_Before_Average)+ \"%\")\n",
    "\n",
    "print(\"---------------------\")\n",
    "\n",
    "print(\"Ordinal Encoding\")\n",
    "O_After_Average = Average(OrdinalAfter) \n",
    "print(\"After: \" + str(O_After_Average) + \"%\")\n",
    "O_Before_Average = Average(OrdinalBefore) \n",
    "print(\"Before: \" + str(O_Before_Average)+ \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the information on Bar chart\n",
    "\n",
    "before = [CB_Before_Average, OH_Before_Average, O_Before_Average]\n",
    "after = [CB_AfterAverage, OH_After_Average, O_After_Average]\n",
    "index = ['CatBoost', 'OneHot', 'Ordinal']\n",
    "df = pd.DataFrame({'Before Split': before,\n",
    "                    'After Split': after}, index=index)\n",
    "ax = df.plot.bar(rot=0)\n",
    "ax.set_ylim([0, 100])\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Encoding Before / After Train-Test Split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50714e80",
   "metadata": {},
   "source": [
    "## Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7f448",
   "metadata": {},
   "source": [
    "#### Average Accuracy: \n",
    "\n",
    "The average accuracy for each of the tests returned as follows:\n",
    "\n",
    "CatBoost Encoding - \n",
    "After:` 72.029%`\n",
    "Before: `72.029%`\n",
    "\n",
    "---------------------\n",
    "OneHot Encoding - \n",
    "After: `72.659%`\n",
    "Before: `72.799%`\n",
    "\n",
    "---------------------\n",
    "Ordinal Encoding - \n",
    "After: `72.301%`\n",
    "Before: `70.91%`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a63f4c",
   "metadata": {},
   "source": [
    "#### CatBoost\n",
    "Both implementations of `CatBoost` encoding returned the exact same values for each test that I ran on the dataset. After tracking ten different tests the average result received was `72.029%`. \n",
    "- From the results I received for my implementation of `CatBoost` encoding using `Categorical Naieve Bayes`, there is no change in accuracy when splitting the data before or after applying the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e459dd",
   "metadata": {},
   "source": [
    "#### OneHot\n",
    "Similar to the above reult outlined for `CatBoost`, the accuracy results were very similar for `OneHot` implemented with `Bernoulli Naive Bayes`.\n",
    "- 8 out of 10 test results were identical, of the two that differed the accuracy for encoding the dataset before splitting between test and train returned marginally greater, at `0.14%` more when compared.\n",
    "- This marginal difference is not sufficient to say what approach is more suited to  `OneHot` encoding. More testing  would need to be completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c57562",
   "metadata": {},
   "source": [
    "#### Ordinal Encoding \n",
    "An improvement in accuracy occured when encoding after splitting the sets while testing my implementation of `OrdinalEncoder` along with `Categorical Naive bayes`.\n",
    "\n",
    "   - This suggests that splitting the data first is a more accurate method when implementing the `OrdinalEncoder` , to prove this hypothesis a larger scale of tests would be required.\n",
    "   - After: `72.301%` Before: `70.91%`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd11a8a",
   "metadata": {},
   "source": [
    "#### Overall\n",
    "\n",
    "My implementations of the encoders achieved similar levels of accuracy for predicting the `Class` target on the `breast-cancer.csv` dataset. Overall, `OneHot` encoding paired with `Bernoulli Naive Bayes`  provided the highest accuracy on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad293df",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "\n",
    "##### Reference - \n",
    "\n",
    "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "\n",
    "Available at:`https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
